{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###############################\n",
    "##### importing libraries #####\n",
    "###############################\n",
    "\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np, numpy.random\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.dataset import Dataset  \n",
    "from torchvision.transforms import Compose\n",
    "torch.backends.cudnn.benchmark=True\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Hyperparameters for federated learning #########\n",
    "num_clients = 10\n",
    "num_selected = 6\n",
    "num_rounds = 150\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "\n",
    "classes_pc = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return (tensor + torch.randn(tensor.size()) * self.std + self.mean)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14621847, 0.19144507, 0.08063636, 0.02670773, 0.0734351 ,\n",
       "       0.02733149, 0.18999231, 0.20267645, 0.0586    , 0.00295702])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.dirichlet(np.ones(num_clients), size=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cifar10():\n",
    "  '''Return CIFAR10 train/test data and labels as numpy arrays'''\n",
    "  data_train = torchvision.datasets.CIFAR10('./data', train=True, download=True)\n",
    "  data_test = torchvision.datasets.CIFAR10('./data', train=False, download=True) \n",
    "  \n",
    "  x_train, y_train = data_train.data.transpose((0,3,1,2)), np.array(data_train.targets)\n",
    "  x_test, y_test = data_test.data.transpose((0,3,1,2)), np.array(data_test.targets)\n",
    "  \n",
    "  return x_train, y_train, x_test, y_test\n",
    "\n",
    "def print_image_data_stats(data_train, labels_train, data_test, labels_test):\n",
    "  print(\"\\nData: \")\n",
    "  print(\" - Train Set: ({},{}), Range: [{:.3f}, {:.3f}], Labels: {},..,{}\".format(\n",
    "    data_train.shape, labels_train.shape, np.min(data_train), np.max(data_train),\n",
    "      np.min(labels_train), np.max(labels_train)))\n",
    "  print(\" - Test Set: ({},{}), Range: [{:.3f}, {:.3f}], Labels: {},..,{}\".format(\n",
    "    data_test.shape, labels_test.shape, np.min(data_train), np.max(data_train),\n",
    "      np.min(labels_test), np.max(labels_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clients_rand(train_len, nclients):\n",
    "  '''\n",
    "  train_len: size of the train data\n",
    "  nclients: number of clients\n",
    "  \n",
    "  Returns: to_ret\n",
    "  \n",
    "  This function creates a random distribution \n",
    "  for the clients, i.e. number of images each client \n",
    "  possess.\n",
    "  '''\n",
    "  client_tmp=[]\n",
    "  sum_=0\n",
    "  #### creating random values for each client ####\n",
    "  for i in range(nclients-1):\n",
    "    tmp=random.randint(10,100)\n",
    "    sum_+=tmp\n",
    "    client_tmp.append(tmp)\n",
    "  sum_+=random.randint(10,100)\n",
    "  client_tmp= np.array(client_tmp)\n",
    "  #### using those random values as weights ####\n",
    "  clients_dist= ((client_tmp/sum_)*train_len).astype(int)\n",
    "  num  = train_len - clients_dist.sum()\n",
    "  to_ret = list(clients_dist)\n",
    "  to_ret.append(num)\n",
    "  return to_ret"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/preserving-data-privacy-in-deep-learning-part-2-6c2e9494398b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_image_data_realwd(data, labels, n_clients=100, verbose=True):\n",
    "  '''\n",
    "  Splits (data, labels) among 'n_clients s.t. every client can holds any number of classes which is trying to simulate real world dataset\n",
    "  Input:\n",
    "    data : [n_data x shape]\n",
    "    labels : [n_data (x 1)] from 0 to n_labels(10)\n",
    "    n_clients : number of clients\n",
    "    verbose : True/False => True for printing some info, False otherwise\n",
    "  Output:\n",
    "    clients_split : splitted client data into desired format\n",
    "  '''\n",
    "  def break_into(n,m):\n",
    "    ''' \n",
    "    return m random integers with sum equal to n \n",
    "    '''\n",
    "    to_ret = [1 for i in range(m)]\n",
    "    for i in range(n-m):\n",
    "        ind = random.randint(0,m-1)\n",
    "        to_ret[ind] += 1\n",
    "    return to_ret\n",
    "\n",
    "  #### constants ####\n",
    "  n_classes = len(set(labels))\n",
    "  classes = list(range(n_classes))\n",
    "  np.random.shuffle(classes)\n",
    "  label_indcs  = [list(np.where(labels==class_)[0]) for class_ in classes]\n",
    "  \n",
    "  #### classes for each client ####\n",
    "  tmp = [np.random.randint(1,10) for i in range(n_clients)]\n",
    "  total_partition = sum(tmp)\n",
    "\n",
    "  #### create partition among classes to fulfill criteria for clients ####\n",
    "  class_partition = break_into(total_partition, len(classes))\n",
    "\n",
    "  #### applying greedy approach first come and first serve ####\n",
    "  class_partition = sorted(class_partition,reverse=True)\n",
    "  class_partition_split = {}\n",
    "\n",
    "  #### based on class partition, partitioning the label indexes ###\n",
    "  for ind, class_ in enumerate(classes):\n",
    "      class_partition_split[class_] = [list(i) for i in np.array_split(label_indcs[ind],class_partition[ind])]\n",
    "      \n",
    "#   print([len(class_partition_split[key]) for key in  class_partition_split.keys()])\n",
    "\n",
    "  clients_split = []\n",
    "  count = 0\n",
    "  for i in range(n_clients):\n",
    "    n = tmp[i]\n",
    "    j = 0\n",
    "    indcs = []\n",
    "\n",
    "    while n>0:\n",
    "        class_ = classes[j]\n",
    "        if len(class_partition_split[class_])>0:\n",
    "            indcs.extend(class_partition_split[class_][-1])\n",
    "            count+=len(class_partition_split[class_][-1])\n",
    "            class_partition_split[class_].pop()\n",
    "            n-=1\n",
    "        j+=1\n",
    "\n",
    "    ##### sorting classes based on the number of examples it has #####\n",
    "    classes = sorted(classes,key=lambda x:len(class_partition_split[x]),reverse=True)\n",
    "    if n>0:\n",
    "        raise ValueError(\" Unable to fulfill the criteria \")\n",
    "    clients_split.append([data[indcs], labels[indcs]])\n",
    "#   print(class_partition_split)\n",
    "#   print(\"total example \",count)\n",
    "\n",
    "\n",
    "  def print_split(clients_split): \n",
    "    print(\"Data split:\")\n",
    "    for i, client in enumerate(clients_split):\n",
    "      split = np.sum(client[1].reshape(1,-1)==np.arange(n_labels).reshape(-1,1), axis=1)\n",
    "      print(\" - Client {}: {}\".format(i,split))\n",
    "    print()\n",
    "      \n",
    "    if verbose:\n",
    "      print_split(clients_split)\n",
    "  \n",
    "  clients_split = np.array(clients_split)\n",
    "  \n",
    "  return clients_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchvision.transforms.functional as T\n",
    "\n",
    "def load_image(infilename, resize=32) :\n",
    "    img = T.resize(Image.open(infilename), size=resize)\n",
    "    img.load()\n",
    "    data = np.asarray(img, dtype=\"uint8\")\n",
    "    return np.transpose(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, random\n",
    "images = glob.glob(\"./noisy_data/small_scale/dead_leaves-mixed/train/0000000000/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_images = np.asarray(list(map(load_image, images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 32, 32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "natural_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x, data, alpha=1.0, use_cuda=True):\n",
    "\n",
    "    '''Compute the mixup data. Return mixed inputs, pairs of targets, and lambda'''\n",
    "    # if alpha > 0.:\n",
    "    #     lam = np.random.beta(alpha, alpha)\n",
    "    # else:\n",
    "    #     lam = 1.\n",
    "    # batch_size = x.size()[0]\n",
    "    # if use_cuda:\n",
    "    #     index = torch.randperm(batch_size).cuda()\n",
    "    # else:\n",
    "    #     index = torch.randperm(batch_size)\n",
    "    low = 0.1\n",
    "    k = 3\n",
    "\n",
    "    dist = np.random.beta(alpha, alpha)\n",
    "    main_weight = .5 + (dist * .25)\n",
    "    a = np.random.rand(k)\n",
    "    a = (a/a.sum()*(1-low*k))\n",
    "    weights = a+low\n",
    "    weights = weights * (1-main_weight)\n",
    "    mixed_x = ((x * main_weight) + np.sum([arr * weights[i] for i, arr in enumerate(np.random.choice(data, k))], axis=0)).astype(np.uint8)\n",
    "    # y_a, y_b = y, y[index]\n",
    "    return mixed_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66090360551415"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.beta(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "low = 0.1\n",
    "k = 3\n",
    "\n",
    "a = np.random.rand(k)\n",
    "a = (a/a.sum()*(1-low*k))\n",
    "weights = a+low\n",
    "weights = weights / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.27834948, 0.27834948, 0.27834948],\n",
       "       [0.27834948, 0.27834948, 0.27834948],\n",
       "       [0.27834948, 0.27834948, 0.27834948]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1 = np.zeros((3, 3))\n",
    "arr2 = np.ones((3, 3))\n",
    "arr3 = np.ones((3, 3))\n",
    "np.sum([arr * weights[i] for i, arr in enumerate([arr1,arr2,arr3])], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddNoise(tensor, mean, std, gaussian_application, natural_image_application):\n",
    "    choice = np.random.rand()\n",
    "    if choice < gaussian_application:\n",
    "        tensor = torch.from_numpy(tensor)\n",
    "        return ((tensor + torch.randn(tensor.size()) * std + mean).numpy()).astype(np.uint8)\n",
    "    elif choice < (gaussian_application + natural_image_application):\n",
    "        return natural_images[np.random.randint(1000)]\n",
    "    else:\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_image_data(data, labels, n_clients=100, classes_per_client=10, shuffle=True, verbose=True):\n",
    "  '''\n",
    "  Splits (data, labels) among 'n_clients s.t. every client can holds 'classes_per_client' number of classes\n",
    "  Input:\n",
    "    data : [n_data x shape]\n",
    "    labels : [n_data (x 1)] from 0 to n_labels\n",
    "    n_clients : number of clients\n",
    "    classes_per_client : number of classes per client\n",
    "    shuffle : True/False => True for shuffling the dataset, False otherwise\n",
    "    verbose : True/False => True for printing some info, False otherwise\n",
    "  Output:\n",
    "    clients_split : client data into desired format\n",
    "  '''\n",
    "  #### constants ####\n",
    "  n_data = data.shape[0]\n",
    "  n_labels = np.max(labels) + 1\n",
    "  # gauss = lambda x, y, z : x + torch.randn(x.size()) * z + y\n",
    "  noise_data = AddNoise(data, 0., 50., .0, .0)\n",
    "\n",
    "  ### client distribution ####\n",
    "  data_per_client = clients_rand(len(data), n_clients)\n",
    "  data_per_client_per_class = [np.maximum(1,nd // classes_per_client) for nd in data_per_client]\n",
    "\n",
    "  # sort for labels\n",
    "  data_idcs = [[] for i in range(n_labels)]\n",
    "  for j, label in enumerate(labels):\n",
    "    data_idcs[label] += [j]\n",
    "  if shuffle:\n",
    "    for idcs in data_idcs:\n",
    "      np.random.shuffle(idcs)\n",
    "\n",
    "  noise_idcs = copy.deepcopy(data_idcs)\n",
    "  # split data among clients\n",
    "  clients_split = []\n",
    "  c = 0\n",
    "  # We want all clients to have this much data for each class\n",
    "  max_data = np.max(data_per_client_per_class)\n",
    "  print(f\"Data Per Client: {data_per_client_per_class}, and goal amount of data each client has per class: {max_data}\")\n",
    "  for i in range(n_clients):\n",
    "    client_idcs = []\n",
    "    share_idcs = []\n",
    "\n",
    "    budget = data_per_client[i]\n",
    "    c = np.random.randint(n_labels)\n",
    "    cl = []\n",
    "    while budget > 0:\n",
    "      take = min(data_per_client_per_class[i], len(data_idcs[c]), budget)\n",
    "\n",
    "      client_idcs += data_idcs[c][:take]\n",
    "      data_idcs[c] = data_idcs[c][take:]\n",
    "\n",
    "      budget -= take\n",
    "      cl.append(c)\n",
    "      if take < max_data:\n",
    "        fill = min((max_data-take), len(noise_idcs[c]))\n",
    "        share_idcs += random.choices(noise_idcs[c], k=fill)\n",
    "      c = (c + 1) % n_labels\n",
    "\n",
    "    # add noise examples\n",
    "    class_list = [x for x in range (0, n_labels)]\n",
    "    noise_classes = [x for x in class_list if x not in cl]\n",
    "    for class_ in noise_classes:\n",
    "      take = min(max_data, len(noise_idcs[class_]))\n",
    "      share_idcs += random.choices(noise_idcs[class_], k=take)\n",
    "\n",
    "    print(f\"Untouched: {len(client_idcs)} Noise: {len(share_idcs)}, Classes: {cl}\")\n",
    "    print(f\"Labels: {np.asarray(np.unique(labels[(client_idcs + share_idcs)], return_counts=True)).T}\")\n",
    "    clients_split += [(np.concatenate((data[client_idcs], noise_data[share_idcs])), labels[(client_idcs + share_idcs)])]\n",
    "\n",
    "  def print_split(clients_split):\n",
    "    print(\"Data split:\")\n",
    "    for i, client in enumerate(clients_split):\n",
    "      split = np.sum(client[1].reshape(1,-1)==np.arange(n_labels).reshape(-1,1), axis=1)\n",
    "      print(\" - Client {}: {}\".format(i,split))\n",
    "    print()\n",
    "\n",
    "    if verbose:\n",
    "      print_split(clients_split)\n",
    "\n",
    "  clients_split = np.array(clients_split)\n",
    "\n",
    "  return clients_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def shuffle_list(data):\n",
    "  '''\n",
    "  This function returns the shuffled data\n",
    "  '''\n",
    "  for i in range(len(data)):\n",
    "    tmp_len= len(data[i][0])\n",
    "    index = [i for i in range(tmp_len)]\n",
    "    random.shuffle(index)\n",
    "    data[i][0],data[i][1] = shuffle_list_data(data[i][0],data[i][1])\n",
    "  return data\n",
    "\n",
    "\n",
    "def shuffle_list_data(x, y):\n",
    "  '''\n",
    "  This function is a helper function, shuffles an\n",
    "  array while maintaining the mapping between x and y\n",
    "  '''\n",
    "  inds = list(range(len(x)))\n",
    "  random.shuffle(inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "  '''\n",
    "  A custom Dataset class for images\n",
    "  inputs : numpy array [n_data x shape]\n",
    "  labels : numpy array [n_data (x 1)]\n",
    "  '''\n",
    "  def __init__(self, inputs, labels, transforms=None):\n",
    "      assert inputs.shape[0] == labels.shape[0]\n",
    "      self.inputs = torch.Tensor(inputs)\n",
    "      self.labels = torch.Tensor(labels).long()\n",
    "      self.transforms = transforms \n",
    "\n",
    "  def __getitem__(self, index):\n",
    "      img, label = self.inputs[index], self.labels[index]\n",
    "\n",
    "      if self.transforms is not None:\n",
    "        img = self.transforms(img)\n",
    "\n",
    "      return (img, label)\n",
    "\n",
    "  def __len__(self):\n",
    "      return self.inputs.shape[0]\n",
    "          \n",
    "\n",
    "def get_default_data_transforms(train=True, verbose=True):\n",
    "  transforms_train = {\n",
    "  'cifar10' : transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))]),#(0.24703223, 0.24348513, 0.26158784)\n",
    "  }\n",
    "  transforms_eval = {    \n",
    "  'cifar10' : transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "  }\n",
    "  if verbose:\n",
    "    print(\"\\nData preprocessing: \")\n",
    "    for transformation in transforms_train['cifar10'].transforms:\n",
    "      print(' -', transformation)\n",
    "    print()\n",
    "\n",
    "  return (transforms_train['cifar10'], transforms_eval['cifar10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_data_loaders(nclients,batch_size,classes_pc=10, real_wd =False ,verbose=True ):\n",
    "  \n",
    "  x_train, y_train, x_test, y_test = get_cifar10()\n",
    "\n",
    "  if verbose:\n",
    "    print_image_data_stats(x_train, y_train, x_test, y_test)\n",
    "\n",
    "  transforms_train, transforms_eval = get_default_data_transforms(verbose=False)\n",
    "  \n",
    "  if real_wd:\n",
    "    split = split_image_data_realwd(x_train, y_train, n_clients=nclients, verbose = verbose)\n",
    "  else:  \n",
    "    split = split_image_data(x_train[:10000], y_train[:10000], n_clients=nclients, classes_per_client=classes_pc, verbose=verbose)\n",
    "  \n",
    "  split_tmp = split #shuffle_list(split)\n",
    "  \n",
    "  client_loaders = [torch.utils.data.DataLoader(CustomImageDataset(x, y, transforms_train), batch_size=batch_size, shuffle=True, drop_last=True) for x, y in split_tmp]\n",
    "  \n",
    "  test_loader  = torch.utils.data.DataLoader(CustomImageDataset(x_test, y_test, transforms_eval), batch_size=100, shuffle=False)\n",
    "\n",
    "  return client_loaders, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = get_cifar10()\n",
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(GaussianNoise(x_train, 0., 50., 1).astype(np.uint8) == x_train).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = AddNoise(x_train, 0., 3., 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image as im\n",
    "# arr = np.ascontiguousarray(arr[0].transpose(1,2,0))\n",
    "# data = im.fromarray(arr, 'RGB')\n",
    "# data.save('gaussian3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GaussianNoise(x_train, 0., 3.).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #############################################################\n",
    "# ##### Creating desired data distribution among clients  #####\n",
    "# #############################################################\n",
    "\n",
    "# # Image augmentation \n",
    "# transform_train = transforms.Compose([\n",
    "#     transforms.RandomCrop(32, padding=4),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "#     transforms.RandomApply([AddGaussianNoise(0., 3.)], p=.8)\n",
    "# ])\n",
    "\n",
    "# # Loading CIFAR10 using torchvision.datasets\n",
    "# traindata = datasets.CIFAR10('./data', train=True, download=True,\n",
    "#                        transform= transform_train)\n",
    "# train_fake_data = datasets.CIFAR10('./data', train=True, download=True\n",
    "#                     )\n",
    "\n",
    "# # Dividing the training data into num_clients, with each client having equal number of images\n",
    "# traindata_split = torch.utils.data.random_split(traindata, np.random.dirichlet(np.ones(num_clients), size=1)[0])\n",
    "\n",
    "# # Creating a pytorch loader for a Deep Learning model\n",
    "# train_loader = [torch.utils.data.DataLoader(x, batch_size=batch_size, shuffle=True) for x in traindata_split]\n",
    "\n",
    "# # Normalizing the test images\n",
    "# transform_test = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "# ])\n",
    "\n",
    "# # Loading the test iamges and thus converting them into a test_loader\n",
    "# test_loader = torch.utils.data.DataLoader(\n",
    "#         datasets.CIFAR10('./data', train=False, transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "#         ), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "\n",
      "Data: \n",
      " - Train Set: ((50000, 3, 32, 32),(50000,)), Range: [0.000, 255.000], Labels: 0,..,9\n",
      " - Test Set: ((10000, 3, 32, 32),(10000,)), Range: [0.000, 255.000], Labels: 0,..,9\n",
      "Data Per Client: [481, 376, 167, 240, 690, 648, 512, 554, 1035, 294], and goal amount of data each client has per class: 1035\n",
      "Untouched: 962 Noise: 9060, Classes: [2, 3]\n",
      "Labels: [[   0 1005]\n",
      " [   1  974]\n",
      " [   2 1035]\n",
      " [   3 1035]\n",
      " [   4  999]\n",
      " [   5  937]\n",
      " [   6 1030]\n",
      " [   7 1001]\n",
      " [   8 1025]\n",
      " [   9  981]]\n",
      "Untouched: 753 Noise: 9351, Classes: [5, 6, 7]\n",
      "Labels: [[   0 1005]\n",
      " [   1  974]\n",
      " [   2 1032]\n",
      " [   3 1016]\n",
      " [   4  999]\n",
      " [   5 1035]\n",
      " [   6 1035]\n",
      " [   7 1002]\n",
      " [   8 1025]\n",
      " [   9  981]]\n",
      "Untouched: 334 Noise: 9730, Classes: [8, 9]\n",
      "Labels: [[   0 1005]\n",
      " [   1  974]\n",
      " [   2 1032]\n",
      " [   3 1016]\n",
      " [   4  999]\n",
      " [   5  937]\n",
      " [   6 1030]\n",
      " [   7 1001]\n",
      " [   8 1035]\n",
      " [   9 1035]]\n",
      "Untouched: 481 Noise: 9575, Classes: [3, 4, 5]\n",
      "Labels: [[   0 1005]\n",
      " [   1  974]\n",
      " [   2 1032]\n",
      " [   3 1035]\n",
      " [   4 1035]\n",
      " [   5  938]\n",
      " [   6 1030]\n",
      " [   7 1001]\n",
      " [   8 1025]\n",
      " [   9  981]]\n",
      "Untouched: 1380 Noise: 8664, Classes: [7, 8]\n",
      "Labels: [[   0 1005]\n",
      " [   1  974]\n",
      " [   2 1032]\n",
      " [   3 1016]\n",
      " [   4  999]\n",
      " [   5  937]\n",
      " [   6 1030]\n",
      " [   7 1035]\n",
      " [   8 1035]\n",
      " [   9  981]]\n",
      "Untouched: 1297 Noise: 8761, Classes: [2, 3, 4]\n",
      "Labels: [[   0 1005]\n",
      " [   1  974]\n",
      " [   2 1035]\n",
      " [   3 1035]\n",
      " [   4 1035]\n",
      " [   5  937]\n",
      " [   6 1030]\n",
      " [   7 1001]\n",
      " [   8 1025]\n",
      " [   9  981]]\n",
      "Untouched: 1025 Noise: 9170, Classes: [1, 2, 3, 4, 5]\n",
      "Labels: [[   0 1005]\n",
      " [   1 1035]\n",
      " [   2 1032]\n",
      " [   3 1016]\n",
      " [   4 1035]\n",
      " [   5 1035]\n",
      " [   6 1030]\n",
      " [   7 1001]\n",
      " [   8 1025]\n",
      " [   9  981]]\n",
      "Untouched: 1108 Noise: 9029, Classes: [3, 4, 5, 6, 7]\n",
      "Labels: [[   0 1005]\n",
      " [   1  974]\n",
      " [   2 1032]\n",
      " [   3 1016]\n",
      " [   4  999]\n",
      " [   5 1035]\n",
      " [   6 1035]\n",
      " [   7 1035]\n",
      " [   8 1025]\n",
      " [   9  981]]\n",
      "Untouched: 2071 Noise: 8062, Classes: [4, 5, 6, 7, 8, 9, 0]\n",
      "Labels: [[   0 1035]\n",
      " [   1  974]\n",
      " [   2 1032]\n",
      " [   3 1016]\n",
      " [   4  999]\n",
      " [   5  937]\n",
      " [   6 1035]\n",
      " [   7 1035]\n",
      " [   8 1035]\n",
      " [   9 1035]]\n",
      "Untouched: 589 Noise: 10537, Classes: [1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1]\n",
      "Labels: [[   0 1035]\n",
      " [   1 2070]\n",
      " [   2 1032]\n",
      " [   3 1016]\n",
      " [   4  999]\n",
      " [   5  937]\n",
      " [   6 1030]\n",
      " [   7 1001]\n",
      " [   8 1025]\n",
      " [   9  981]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34789/1086344958.py:80: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  clients_split = np.array(clients_split)\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = get_data_loaders(num_clients, batch_size, classes_pc=2, real_wd=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images, labels = next(iter(train_loader[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#################################\n",
    "##### Neural Network model #####\n",
    "#################################\n",
    "\n",
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        output = F.log_softmax(out, dim=1)\n",
    "        return output\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_update(client_model, optimizer, train_loader, epoch=5):\n",
    "    \"\"\"\n",
    "    This function updates/trains client model on client data\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for e in range(epoch):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output = client_model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def server_aggregate(global_model, client_models):\n",
    "    \"\"\"\n",
    "    This function has aggregation method 'mean'\n",
    "    \"\"\"\n",
    "    ### This will take simple mean of the weights of models ###\n",
    "    global_dict = global_model.state_dict()\n",
    "    for k in global_dict.keys():\n",
    "        global_dict[k] = torch.stack([client_models[i].state_dict()[k].float() for i in range(len(client_models))], 0).mean(0)\n",
    "    global_model.load_state_dict(global_dict)\n",
    "    for model in client_models:\n",
    "        model.load_state_dict(global_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test(global_model, test_loader):\n",
    "    \"\"\"This function test the global model on test data and returns test loss and test accuracy \"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            output = global_model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    acc = correct / len(test_loader.dataset)\n",
    "\n",
    "    return test_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms, utils, datasets\n",
    "from argparse import ArgumentParser\n",
    "from torchvision import transforms as tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientUpdate(object):\n",
    "    def __init__(self, dataset, batchSize, learning_rate, epochs, sch_flag):\n",
    "        self.train_loader = dataset\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.sch_flag = sch_flag\n",
    "\n",
    "    def train(self, model):\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        # optimizer = torch.optim.SGD(model.parameters(), lr=self.learning_rate, momentum=0.95, weight_decay = 5e-4)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=self.learning_rate)\n",
    "        # if self.sch_flag == True:\n",
    "        #    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5)\n",
    "        # my_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.99)\n",
    "        e_loss = []\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "\n",
    "            train_loss = 0.0\n",
    "\n",
    "            model.train()\n",
    "            for data, labels in self.train_loader:\n",
    "                if data.size()[0] < 2:\n",
    "                    continue;\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    data, labels = data.cuda(), labels.cuda()\n",
    "\n",
    "                # clear the gradients\n",
    "                optimizer.zero_grad()\n",
    "                # make a forward pass\n",
    "                output = model(data)\n",
    "                # calculate the loss\n",
    "                loss = criterion(output, labels)\n",
    "                # do a backwards pass\n",
    "                loss.backward()\n",
    "                # perform a single optimization step\n",
    "                optimizer.step()\n",
    "                # update training loss\n",
    "                train_loss += loss.item() * data.size(0)\n",
    "                # if self.sch_flag == True:\n",
    "                #  scheduler.step(train_loss)\n",
    "            # average losses\n",
    "            train_loss = train_loss / len(self.train_loader.dataset)\n",
    "            e_loss.append(train_loss)\n",
    "\n",
    "            # self.learning_rate = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        total_loss = sum(e_loss) / len(e_loss)\n",
    "\n",
    "        return model.state_dict(), total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(model, dataset, bs, criterion, num_classes, classes):\n",
    "    # test loss\n",
    "    test_loss = 0.0\n",
    "    correct_class = list(0. for i in range(num_classes))\n",
    "    total_class = list(0. for i in range(num_classes))\n",
    "\n",
    "    test_loader = DataLoader(dataset, batch_size=bs)\n",
    "    l = len(test_loader)\n",
    "    model.eval()\n",
    "    for data, labels in test_loader:\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            data, labels = data.cuda(), labels.cuda()\n",
    "\n",
    "        output = model(data)\n",
    "        loss = criterion(output, labels)\n",
    "        test_loss += loss.item() * data.size(0)\n",
    "\n",
    "        _, pred = torch.max(output, 1)\n",
    "\n",
    "        correct_tensor = pred.eq(labels.data.view_as(pred))\n",
    "        correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(\n",
    "            correct_tensor.cpu().numpy())\n",
    "\n",
    "        # test accuracy for each object class\n",
    "        for i in range(num_classes):\n",
    "            label = labels.data[i]\n",
    "            correct_class[label] += correct[i].item()\n",
    "            total_class[label] += 1\n",
    "\n",
    "    # avg test loss\n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "\n",
    "    return 100. * np.sum(correct_class) / np.sum(total_class), test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, rounds, batch_size, lr, ds, C, K, E, plt_title, plt_color, cifar_data_test,\n",
    "             test_batch_size, criterion, num_classes, classes_test, sch_flag):\n",
    "    \"\"\"\n",
    "    Function implements the Federated Averaging Algorithm from the FedAvg paper.\n",
    "    Specifically, this function is used for the server side training and weight update\n",
    "\n",
    "    Params:\n",
    "      - model:           PyTorch model to train\n",
    "      - rounds:          Number of communication rounds for the client update\n",
    "      - batch_size:      Batch size for client update training\n",
    "      - lr:              Learning rate used for client update training\n",
    "      - ds:              Dataset used for training\n",
    "      - data_dict:       Type of data partition used for training (IID or non-IID)\n",
    "      - C:               Fraction of clients randomly chosen to perform computation on each round\n",
    "      - K:               Total number of clients\n",
    "      - E:               Number of training passes each client makes over its local dataset per round\n",
    "      - tb_writer_name:  Directory name to save the tensorboard logs\n",
    "    Returns:\n",
    "      - model:           Trained model on the server\n",
    "    \"\"\"\n",
    "\n",
    "    # global model weights\n",
    "    global_weights = model.state_dict()\n",
    "\n",
    "    # training loss\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    test_accuracy = []\n",
    "    best_accuracy = 0\n",
    "    # measure time\n",
    "    start = time.time()\n",
    "\n",
    "    for curr_round in range(1, rounds + 1):\n",
    "        w, local_loss = [], []\n",
    "        # Retrieve the number of clients participating in the current training\n",
    "        m = max(int(C * K), 1)\n",
    "        # Sample a subset of K clients according with the value defined before\n",
    "        S_t = np.random.choice(range(K), m, replace=False)\n",
    "        # For the selected clients start a local training\n",
    "        for k in S_t:\n",
    "            # Compute a local update\n",
    "            local_update = ClientUpdate(dataset=ds[k], batchSize=batch_size, learning_rate=lr, epochs=E,\n",
    "                                        sch_flag=sch_flag)\n",
    "            # Update means retrieve the values of the network weights\n",
    "            weights, loss = local_update.train(model=copy.deepcopy(model))\n",
    "\n",
    "            w.append(copy.deepcopy(weights))\n",
    "            local_loss.append(copy.deepcopy(loss))\n",
    "        # lr = 0.999*lr\n",
    "        # updating the global weights\n",
    "        weights_avg = copy.deepcopy(w[0])\n",
    "        for k in weights_avg.keys():\n",
    "            for i in range(1, len(w)):\n",
    "                weights_avg[k] += w[i][k]\n",
    "\n",
    "            weights_avg[k] = torch.div(weights_avg[k], len(w))\n",
    "\n",
    "        global_weights = weights_avg\n",
    "\n",
    "        if curr_round == 200:\n",
    "            lr = lr / 2\n",
    "            E = E - 1\n",
    "\n",
    "        if curr_round == 300:\n",
    "            lr = lr / 2\n",
    "            E = E - 2\n",
    "\n",
    "        if curr_round == 400:\n",
    "            lr = lr / 5\n",
    "            E = E - 3\n",
    "\n",
    "        # move the updated weights to our model state dict\n",
    "        model.load_state_dict(global_weights)\n",
    "\n",
    "        # loss\n",
    "        loss_avg = sum(local_loss) / len(local_loss)\n",
    "        # print('Round: {}... \\tAverage Loss: {}'.format(curr_round, round(loss_avg, 3)), lr)\n",
    "        train_loss.append(loss_avg)\n",
    "\n",
    "        t_accuracy, t_loss = testing(model, cifar_data_test, test_batch_size, criterion, num_classes, classes_test)\n",
    "        test_accuracy.append(t_accuracy)\n",
    "        test_loss.append(t_loss)\n",
    "\n",
    "        if best_accuracy < t_accuracy:\n",
    "            best_accuracy = t_accuracy\n",
    "        # torch.save(model.state_dict(), plt_title)\n",
    "        print(curr_round, loss_avg, t_loss, test_accuracy[0], best_accuracy)\n",
    "        # print('best_accuracy:', best_accuracy, '---Round:', curr_round, '---lr', lr, '----localEpocs--', E)\n",
    "\n",
    "    end = time.time()\n",
    "    plt.rcParams.update({'font.size': 8})\n",
    "    fig, ax = plt.subplots()\n",
    "    x_axis = np.arange(1, rounds + 1)\n",
    "    y_axis1 = np.array(train_loss)\n",
    "    y_axis2 = np.array(test_accuracy)\n",
    "    y_axis3 = np.array(test_loss)\n",
    "\n",
    "    ax.plot(x_axis, y_axis1, 'tab:' + 'green', label='train_loss')\n",
    "    ax.plot(x_axis, y_axis2, 'tab:' + 'blue', label='test_accuracy')\n",
    "    ax.plot(x_axis, y_axis3, 'tab:' + 'red', label='test_loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    ax.set(xlabel='Number of Rounds', ylabel='Train Loss',\n",
    "           title=plt_title)\n",
    "    ax.grid()\n",
    "    # fig.savefig(plt_title+'.jpg', format='jpg')\n",
    "    print(\"Training Done!\")\n",
    "    print(\"Total time taken to Train: {}\".format(end - start))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGroupNorm(nn.Module):\n",
    "    def __init__(self, num_channels):\n",
    "        super(MyGroupNorm, self).__init__()\n",
    "        self.norm = nn.GroupNorm(num_groups=2, num_channels=num_channels,\n",
    "                                 eps=1e-5, affine=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "noniid_bn_comm_rounds_100_clientfr_0.1_numclients_10_clientepochs_20_clientbs_64_clientLR_0.001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 62\u001b[0m\n\u001b[1;32m     57\u001b[0m plot_str \u001b[39m=\u001b[39m partition \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m norm \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcomm_rounds_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(commrounds) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_clientfr_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\n\u001b[1;32m     58\u001b[0m     clientfr) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_numclients_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(numclient) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_clientepochs_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\n\u001b[1;32m     59\u001b[0m     clientepochs) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_clientbs_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(clientbs) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_clientLR_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(clientlr)\n\u001b[1;32m     60\u001b[0m \u001b[39mprint\u001b[39m(plot_str)\n\u001b[0;32m---> 62\u001b[0m trained_model \u001b[39m=\u001b[39m training(cifar_cnn, H[\u001b[39m0\u001b[39;49m], H[\u001b[39m4\u001b[39;49m], H[\u001b[39m5\u001b[39;49m], train_loader, H[\u001b[39m1\u001b[39;49m], H[\u001b[39m2\u001b[39;49m], H[\u001b[39m3\u001b[39;49m], plot_str,\n\u001b[1;32m     63\u001b[0m                             \u001b[39m\"\u001b[39;49m\u001b[39mgreen\u001b[39;49m\u001b[39m\"\u001b[39;49m, cifar_data_test, \u001b[39m128\u001b[39;49m, criterion, num_classes, classes_test, sch_flag)\n",
      "Cell \u001b[0;32mIn[39], line 45\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(model, rounds, batch_size, lr, ds, C, K, E, plt_title, plt_color, cifar_data_test, test_batch_size, criterion, num_classes, classes_test, sch_flag)\u001b[0m\n\u001b[1;32m     42\u001b[0m local_update \u001b[39m=\u001b[39m ClientUpdate(dataset\u001b[39m=\u001b[39mds[k], batchSize\u001b[39m=\u001b[39mbatch_size, learning_rate\u001b[39m=\u001b[39mlr, epochs\u001b[39m=\u001b[39mE,\n\u001b[1;32m     43\u001b[0m                             sch_flag\u001b[39m=\u001b[39msch_flag)\n\u001b[1;32m     44\u001b[0m \u001b[39m# Update means retrieve the values of the network weights\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m weights, loss \u001b[39m=\u001b[39m local_update\u001b[39m.\u001b[39;49mtrain(model\u001b[39m=\u001b[39;49mcopy\u001b[39m.\u001b[39;49mdeepcopy(model))\n\u001b[1;32m     47\u001b[0m w\u001b[39m.\u001b[39mappend(copy\u001b[39m.\u001b[39mdeepcopy(weights))\n\u001b[1;32m     48\u001b[0m local_loss\u001b[39m.\u001b[39mappend(copy\u001b[39m.\u001b[39mdeepcopy(loss))\n",
      "Cell \u001b[0;32mIn[37], line 32\u001b[0m, in \u001b[0;36mClientUpdate.train\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     30\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     31\u001b[0m \u001b[39m# make a forward pass\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m output \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     33\u001b[0m \u001b[39m# calculate the loss\u001b[39;00m\n\u001b[1;32m     34\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, labels)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1423\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1421\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1422\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1423\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1424\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/models/resnet.py:276\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    274\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer2(x)\n\u001b[1;32m    275\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer3(x)\n\u001b[0;32m--> 276\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer4(x)\n\u001b[1;32m    278\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavgpool(x)\n\u001b[1;32m    279\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1423\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1421\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1422\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1423\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1424\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1423\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1421\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1422\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1423\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1424\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/models/resnet.py:146\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    144\u001b[0m     identity \u001b[39m=\u001b[39m x\n\u001b[0;32m--> 146\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)\n\u001b[1;32m    147\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(out)\n\u001b[1;32m    148\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(out)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1423\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1421\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1422\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1423\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1424\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# parser = ArgumentParser()\n",
    "# parser.add_argument('--norm', default=\"bn\")\n",
    "# parser.add_argument('--partition', default=\"noniid\")\n",
    "# parser.add_argument('--client_number', default=100)\n",
    "# parser.add_argument('--alpha_partition', default=0.5)\n",
    "# parser.add_argument('--commrounds', type=int, default=100)\n",
    "# parser.add_argument('--clientfr', type=float, default=0.1)\n",
    "# parser.add_argument('--numclient', type=int, default=100)\n",
    "# parser.add_argument('--clientepochs', type=int, default=20)\n",
    "# parser.add_argument('--clientbs', type=int, default=64)\n",
    "# parser.add_argument('--clientlr', type=float, default=0.001)\n",
    "# parser.add_argument('--sch_flag', default=False)\n",
    "# args = parser.parse_args()\n",
    "\n",
    "norm = \"bn\"\n",
    "partition = \"noniid\"\n",
    "alpha_partition = 0.5\n",
    "commrounds = 100\n",
    "clientfr = 0.1\n",
    "numclient = num_clients\n",
    "clientepochs = 20\n",
    "clientbs = 64\n",
    "clientlr = 0.001\n",
    "sch_flag = False\n",
    "\n",
    "stats = ((0.49139968, 0.48215841, 0.44653091), (0.24703223, 0.24348513, 0.26158784))\n",
    "\n",
    "transforms_cifar_train = tt.Compose([tt.ToTensor(),\n",
    "                                         tt.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
    "                                         tt.RandomHorizontalFlip(p=0.5),\n",
    "                                         tt.Normalize(*stats)])\n",
    "transforms_cifar_test = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "        transforms.Normalize(*stats)])\n",
    "\n",
    "cifar_data_train = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms_cifar_train)\n",
    "cifar_data_test = datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms_cifar_test)\n",
    "\n",
    "classes = np.array(list(cifar_data_train.class_to_idx.values()))\n",
    "classes_test = np.array(list(cifar_data_test.class_to_idx.values()))\n",
    "num_classes = len(classes_test)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Hyperparameters_List (H) = [rounds, client_fraction, number_of_clients, number_of_training_rounds_local, local_batch_size, lr_client]\n",
    "H = [commrounds, clientfr, numclient, clientepochs, clientbs, clientlr]\n",
    "\n",
    "# if norm == 'gn':\n",
    "#     cifar_cnn = resnet.ResNet(resnet.Bottleneck, [3, 4, 6, 3], num_classes=10, zero_init_residual=False, groups=1,\n",
    "#                                 width_per_group=64, replace_stride_with_dilation=None, norm_layer=MyGroupNorm)\n",
    "# else:\n",
    "cifar_cnn = resnet.ResNet(resnet.Bottleneck, [3, 4, 6, 3], num_classes=10, zero_init_residual=False, groups=1,\n",
    "                                width_per_group=64, replace_stride_with_dilation=None)\n",
    "\n",
    "cifar_cnn.cuda()\n",
    "\n",
    "plot_str = partition + '_' + norm + '_' + 'comm_rounds_' + str(commrounds) + '_clientfr_' + str(\n",
    "    clientfr) + '_numclients_' + str(numclient) + '_clientepochs_' + str(\n",
    "    clientepochs) + '_clientbs_' + str(clientbs) + '_clientLR_' + str(clientlr)\n",
    "print(plot_str)\n",
    "\n",
    "trained_model = training(cifar_cnn, H[0], H[4], H[5], train_loader, H[1], H[2], H[3], plot_str,\n",
    "                            \"green\", cifar_data_test, 128, criterion, num_classes, classes_test, sch_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iid_partition(dataset, clients):\n",
    "    \"\"\"\n",
    "    I.I.D paritioning of data over clients\n",
    "    Shuffle the data\n",
    "    Split it between clients\n",
    "\n",
    "    params:\n",
    "      - dataset (torch.utils.Dataset): Dataset containing the Images\n",
    "      - clients (int): Number of Clients to split the data between\n",
    "\n",
    "    returns:\n",
    "      - Dictionary of image indexes for each client\n",
    "    \"\"\"\n",
    "\n",
    "    num_items_per_client = int(len(dataset) / clients)\n",
    "    client_dict = {}\n",
    "    image_idxs = [i for i in range(len(dataset))]\n",
    "\n",
    "    for i in range(clients):\n",
    "        client_dict[i] = set(np.random.choice(image_idxs, num_items_per_client, replace=False))\n",
    "        image_idxs = list(set(image_idxs) - client_dict[i])\n",
    "\n",
    "    return client_dict\n",
    "\n",
    "\n",
    "def non_iid_partition(dataset, n_nets, alpha):\n",
    "    \"\"\"\n",
    "        :param dataset: dataset name\n",
    "        :param n_nets: number of clients\n",
    "        :param alpha: beta parameter of the Dirichlet distribution\n",
    "        :return: dictionary containing the indexes for each client\n",
    "    \"\"\"\n",
    "    y_train = np.array(dataset.targets)\n",
    "    min_size = 0\n",
    "    K = 10\n",
    "    N = y_train.shape[0]\n",
    "    net_dataidx_map = {}\n",
    "\n",
    "    while min_size < 10:\n",
    "        idx_batch = [[] for _ in range(n_nets)]\n",
    "        # for each class in the dataset\n",
    "        for k in range(K):\n",
    "            idx_k = np.where(y_train == k)[0]\n",
    "            np.random.shuffle(idx_k)\n",
    "            proportions = np.random.dirichlet(np.repeat(alpha, n_nets))\n",
    "            ## Balance\n",
    "            proportions = np.array([p * (len(idx_j) < N / n_nets) for p, idx_j in zip(proportions, idx_batch)])\n",
    "            proportions = proportions / proportions.sum()\n",
    "            proportions = (np.cumsum(proportions) * len(idx_k)).astype(int)[:-1]\n",
    "            idx_batch = [idx_j + idx.tolist() for idx_j, idx in zip(idx_batch, np.split(idx_k, proportions))]\n",
    "            min_size = min([len(idx_j) for idx_j in idx_batch])\n",
    "\n",
    "    for j in range(n_nets):\n",
    "        np.random.shuffle(idx_batch[j])\n",
    "        net_dataidx_map[j] = np.array(idx_batch[j])\n",
    "\n",
    "    # net_dataidx_map is a dictionary of length #of clients: {key: int, value: [list of indexes mapping the data among the workers}\n",
    "    # traindata_cls_counts is a dictionary of length #of clients, basically assesses how the different labels are distributed among\n",
    "    # the client, counting the total number of examples per class in each client.\n",
    "    return net_dataidx_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset, idxs):\n",
    "        self.dataset = dataset\n",
    "        self.idxs = list(idxs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idxs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image, label = self.dataset[self.idxs[item]]\n",
    "        return image, label\n",
    "\n",
    "\n",
    "class ClientUpdate(object):\n",
    "    def __init__(self, dataset, batchSize, learning_rate, epochs, idxs, sch_flag):\n",
    "        self.train_loader = DataLoader(CustomDataset(dataset, idxs), batch_size=batchSize, shuffle=True)\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.sch_flag = sch_flag\n",
    "\n",
    "    def train(self, model):\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        # optimizer = torch.optim.SGD(model.parameters(), lr=self.learning_rate, momentum=0.95, weight_decay = 5e-4)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=self.learning_rate)\n",
    "        # if self.sch_flag == True:\n",
    "        #    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5)\n",
    "        # my_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.99)\n",
    "        e_loss = []\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "\n",
    "            train_loss = 0.0\n",
    "\n",
    "            model.train()\n",
    "            for data, labels in self.train_loader:\n",
    "                if data.size()[0] < 2:\n",
    "                    continue;\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    data, labels = data.cuda(), labels.cuda()\n",
    "\n",
    "                # clear the gradients\n",
    "                optimizer.zero_grad()\n",
    "                # make a forward pass\n",
    "                output = model(data)\n",
    "                # calculate the loss\n",
    "                loss = criterion(output, labels)\n",
    "                # do a backwards pass\n",
    "                loss.backward()\n",
    "                # perform a single optimization step\n",
    "                optimizer.step()\n",
    "                # update training loss\n",
    "                train_loss += loss.item() * data.size(0)\n",
    "                # if self.sch_flag == True:\n",
    "                #  scheduler.step(train_loss)\n",
    "            # average losses\n",
    "            train_loss = train_loss / len(self.train_loader.dataset)\n",
    "            e_loss.append(train_loss)\n",
    "\n",
    "            # self.learning_rate = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        total_loss = sum(e_loss) / len(e_loss)\n",
    "\n",
    "        return model.state_dict(), total_loss\n",
    "\n",
    "\n",
    "\"\"\"### Server Side Training\n",
    "\n",
    "Following Algorithm 1 from the paper\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def training(model, rounds, batch_size, lr, ds, data_dict, C, K, E, plt_title, plt_color, cifar_data_test,\n",
    "             test_batch_size, criterion, num_classes, classes_test, sch_flag):\n",
    "    \"\"\"\n",
    "    Function implements the Federated Averaging Algorithm from the FedAvg paper.\n",
    "    Specifically, this function is used for the server side training and weight update\n",
    "\n",
    "    Params:\n",
    "      - model:           PyTorch model to train\n",
    "      - rounds:          Number of communication rounds for the client update\n",
    "      - batch_size:      Batch size for client update training\n",
    "      - lr:              Learning rate used for client update training\n",
    "      - ds:              Dataset used for training\n",
    "      - data_dict:       Type of data partition used for training (IID or non-IID)\n",
    "      - C:               Fraction of clients randomly chosen to perform computation on each round\n",
    "      - K:               Total number of clients\n",
    "      - E:               Number of training passes each client makes over its local dataset per round\n",
    "      - tb_writer_name:  Directory name to save the tensorboard logs\n",
    "    Returns:\n",
    "      - model:           Trained model on the server\n",
    "    \"\"\"\n",
    "\n",
    "    # global model weights\n",
    "    global_weights = model.state_dict()\n",
    "\n",
    "    # training loss\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    test_accuracy = []\n",
    "    best_accuracy = 0\n",
    "    # measure time\n",
    "    start = time.time()\n",
    "\n",
    "    for curr_round in range(1, rounds + 1):\n",
    "        w, local_loss = [], []\n",
    "        # Retrieve the number of clients participating in the current training\n",
    "        m = max(int(C * K), 1)\n",
    "        # Sample a subset of K clients according with the value defined before\n",
    "        S_t = np.random.choice(range(K), m, replace=False)\n",
    "        # For the selected clients start a local training\n",
    "        for k in S_t:\n",
    "            # Compute a local update\n",
    "            local_update = ClientUpdate(dataset=ds, batchSize=batch_size, learning_rate=lr, epochs=E, idxs=data_dict[k],\n",
    "                                        sch_flag=sch_flag)\n",
    "            # Update means retrieve the values of the network weights\n",
    "            weights, loss = local_update.train(model=copy.deepcopy(model))\n",
    "\n",
    "            w.append(copy.deepcopy(weights))\n",
    "            local_loss.append(copy.deepcopy(loss))\n",
    "        # lr = 0.999*lr\n",
    "        # updating the global weights\n",
    "        weights_avg = copy.deepcopy(w[0])\n",
    "        for k in weights_avg.keys():\n",
    "            for i in range(1, len(w)):\n",
    "                weights_avg[k] += w[i][k]\n",
    "\n",
    "            weights_avg[k] = torch.div(weights_avg[k], len(w))\n",
    "\n",
    "        global_weights = weights_avg\n",
    "\n",
    "        if curr_round == 200:\n",
    "            lr = lr / 2\n",
    "            E = E - 1\n",
    "\n",
    "        if curr_round == 300:\n",
    "            lr = lr / 2\n",
    "            E = E - 2\n",
    "\n",
    "        if curr_round == 400:\n",
    "            lr = lr / 5\n",
    "            E = E - 3\n",
    "\n",
    "        # move the updated weights to our model state dict\n",
    "        model.load_state_dict(global_weights)\n",
    "\n",
    "        # loss\n",
    "        loss_avg = sum(local_loss) / len(local_loss)\n",
    "        # print('Round: {}... \\tAverage Loss: {}'.format(curr_round, round(loss_avg, 3)), lr)\n",
    "        train_loss.append(loss_avg)\n",
    "\n",
    "        t_accuracy, t_loss = testing(model, cifar_data_test, test_batch_size, criterion, num_classes, classes_test)\n",
    "        test_accuracy.append(t_accuracy)\n",
    "        test_loss.append(t_loss)\n",
    "\n",
    "        if best_accuracy < t_accuracy:\n",
    "            best_accuracy = t_accuracy\n",
    "        # torch.save(model.state_dict(), plt_title)\n",
    "        print(curr_round, loss_avg, t_loss, test_accuracy[0], best_accuracy)\n",
    "        # print('best_accuracy:', best_accuracy, '---Round:', curr_round, '---lr', lr, '----localEpocs--', E)\n",
    "\n",
    "    end = time.time()\n",
    "    plt.rcParams.update({'font.size': 8})\n",
    "    fig, ax = plt.subplots()\n",
    "    x_axis = np.arange(1, rounds + 1)\n",
    "    y_axis1 = np.array(train_loss)\n",
    "    y_axis2 = np.array(test_accuracy)\n",
    "    y_axis3 = np.array(test_loss)\n",
    "\n",
    "    ax.plot(x_axis, y_axis1, 'tab:' + 'green', label='train_loss')\n",
    "    ax.plot(x_axis, y_axis2, 'tab:' + 'blue', label='test_accuracy')\n",
    "    ax.plot(x_axis, y_axis3, 'tab:' + 'red', label='test_loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    ax.set(xlabel='Number of Rounds', ylabel='Train Loss',\n",
    "           title=plt_title)\n",
    "    ax.grid()\n",
    "    # fig.savefig(plt_title+'.jpg', format='jpg')\n",
    "    print(\"Training Done!\")\n",
    "    print(\"Total time taken to Train: {}\".format(end - start))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\"\"\"## ResNet50 Model (W & W/O GN)\n",
    "\n",
    "> Indented block\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class MyGroupNorm(nn.Module):\n",
    "    def __init__(self, num_channels):\n",
    "        super(MyGroupNorm, self).__init__()\n",
    "        self.norm = nn.GroupNorm(num_groups=2, num_channels=num_channels,\n",
    "                                 eps=1e-5, affine=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\"\"\"## Testing Loop\"\"\"\n",
    "\n",
    "\n",
    "def testing(model, dataset, bs, criterion, num_classes, classes):\n",
    "    # test loss\n",
    "    test_loss = 0.0\n",
    "    correct_class = list(0. for i in range(num_classes))\n",
    "    total_class = list(0. for i in range(num_classes))\n",
    "\n",
    "    test_loader = DataLoader(dataset, batch_size=bs)\n",
    "    l = len(test_loader)\n",
    "    model.eval()\n",
    "    for data, labels in test_loader:\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            data, labels = data.cuda(), labels.cuda()\n",
    "\n",
    "        output = model(data)\n",
    "        loss = criterion(output, labels)\n",
    "        test_loss += loss.item() * data.size(0)\n",
    "\n",
    "        _, pred = torch.max(output, 1)\n",
    "\n",
    "        correct_tensor = pred.eq(labels.data.view_as(pred))\n",
    "        correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(\n",
    "            correct_tensor.cpu().numpy())\n",
    "\n",
    "        # test accuracy for each object class\n",
    "        for i in range(num_classes):\n",
    "            label = labels.data[i]\n",
    "            correct_class[label] += correct[i].item()\n",
    "            total_class[label] += 1\n",
    "\n",
    "    # avg test loss\n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "\n",
    "    return 100. * np.sum(correct_class) / np.sum(total_class), test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "iid_bn_comm_rounds_100_clientfr_0.1_numclients_10_clientepochs_20_clientbs_64_clientLR_0.001\n",
      "1 2.028981917095184 3.526456664276123 29.367088607594937 29.367088607594937\n",
      "2 1.9885620866298677 7.217822661590576 29.367088607594937 29.367088607594937\n",
      "3 1.5408104944705963 2.1895949710845946 29.367088607594937 37.34177215189873\n",
      "4 1.939948887062073 2.457892044258118 29.367088607594937 37.34177215189873\n",
      "5 1.9644945016384123 2.1960014999389648 29.367088607594937 37.34177215189873\n",
      "6 1.697844091081619 89.16677650146484 29.367088607594937 37.34177215189873\n",
      "7 1.430200507712364 2.2254912780761718 29.367088607594937 37.34177215189873\n",
      "8 1.4391789371013641 3.73610962638855 29.367088607594937 38.9873417721519\n",
      "9 1.1324253946542737 2.300172336387634 29.367088607594937 41.51898734177215\n",
      "10 0.5529472256302833 2.80307884349823 29.367088607594937 41.51898734177215\n",
      "11 0.998599880051613 2.066993391990662 29.367088607594937 41.64556962025316\n",
      "12 1.129520971775055 2.0222667518615722 29.367088607594937 43.79746835443038\n",
      "13 1.1830985749244687 2.2750800294876097 29.367088607594937 43.79746835443038\n",
      "14 1.0246777820825579 2.071965718078613 29.367088607594937 44.936708860759495\n",
      "15 0.8361583763480187 2.309088395881653 29.367088607594937 45.063291139240505\n",
      "16 0.9644634509921077 3.2321288791656495 29.367088607594937 45.063291139240505\n",
      "17 1.0947528019666672 1.9942831237792968 29.367088607594937 47.08860759493671\n",
      "18 0.8593241458058356 2.4746696277618407 29.367088607594937 47.08860759493671\n",
      "19 0.7762649242520333 2.1532287939071657 29.367088607594937 47.848101265822784\n",
      "20 0.8899692844390868 7.834720397567749 29.367088607594937 47.848101265822784\n",
      "21 0.4910593434989452 3.4057221746444704 29.367088607594937 47.848101265822784\n",
      "22 1.0100380991637705 2.163717880821228 29.367088607594937 48.860759493670884\n",
      "23 0.9643668006062509 2.018265454864502 29.367088607594937 48.860759493670884\n",
      "24 0.8207094628989695 2.2235018283843995 29.367088607594937 48.860759493670884\n",
      "25 0.7231706367850304 2.266934173965454 29.367088607594937 48.860759493670884\n",
      "26 0.6895423014760017 3.0246143814086914 29.367088607594937 48.860759493670884\n",
      "27 0.6681384472072125 2.336318636703491 29.367088607594937 48.860759493670884\n",
      "28 0.4896121395111083 2.4460691146850584 29.367088607594937 48.860759493670884\n",
      "29 1.0167436502933505 1.9787876750946045 29.367088607594937 48.9873417721519\n",
      "30 0.4546035230159761 2.5366510944366456 29.367088607594937 48.9873417721519\n",
      "31 1.0136729530334472 2.0131646640777587 29.367088607594937 48.9873417721519\n",
      "32 0.9041762721180916 2.442817502784729 29.367088607594937 48.9873417721519\n",
      "33 0.9553310282826424 1.9669044351577758 29.367088607594937 49.11392405063291\n",
      "34 0.8500121987462043 2.0275366622924804 29.367088607594937 49.87341772151899\n",
      "35 0.6113314609587193 2.3720140033721924 29.367088607594937 52.278481012658226\n",
      "36 0.4960930657982826 2.6909055152893067 29.367088607594937 52.278481012658226\n",
      "37 0.5748314301967621 2.3675368270874024 29.367088607594937 52.278481012658226\n",
      "38 0.6179406952023505 2.1656864250183108 29.367088607594937 52.278481012658226\n",
      "39 0.4026438238501549 2.8366143493652345 29.367088607594937 52.278481012658226\n",
      "40 0.391037095206976 2.7333979717254637 29.367088607594937 52.278481012658226\n",
      "41 0.672098317205906 2.494152131652832 29.367088607594937 52.278481012658226\n",
      "42 0.3449419168263673 2.523896138381958 29.367088607594937 52.278481012658226\n",
      "43 1.024854391527176 7.577894165039062 29.367088607594937 52.278481012658226\n",
      "44 0.9358401497483252 2.8993902910232543 29.367088607594937 52.278481012658226\n",
      "45 0.8982161670207978 2.051049501800537 29.367088607594937 52.278481012658226\n",
      "46 0.8808830894947052 2.293740337753296 29.367088607594937 52.278481012658226\n",
      "47 0.6413582565426826 3.062104291534424 29.367088607594937 52.278481012658226\n",
      "48 0.6309879550755024 2.2875888483047486 29.367088607594937 52.278481012658226\n",
      "49 0.5927662976026535 2.3054295293807985 29.367088607594937 52.278481012658226\n",
      "50 0.8133045685887337 2.217040267753601 29.367088607594937 52.278481012658226\n",
      "51 0.4985929683342577 2.414715756225586 29.367088607594937 52.278481012658226\n",
      "52 0.48014578255712986 2.763018408203125 29.367088607594937 52.278481012658226\n",
      "53 0.42783269872069357 2.7958470836639404 29.367088607594937 52.278481012658226\n",
      "54 0.5157441033512352 2.3880428340911863 29.367088607594937 53.41772151898734\n",
      "55 0.8100942811012268 2.04807678565979 29.367088607594937 53.924050632911396\n",
      "56 0.7787661502599716 2.042680781173706 29.367088607594937 53.924050632911396\n",
      "57 0.36440593648254876 2.5419571464538575 29.367088607594937 53.924050632911396\n",
      "58 0.628018976688385 2.0751061016082764 29.367088607594937 55.69620253164557\n",
      "59 0.1896660814914852 2.756131755065918 29.367088607594937 55.69620253164557\n",
      "60 0.514966421058774 2.3187427421569824 29.367088607594937 55.69620253164557\n",
      "61 0.23831866622567177 2.603932320022583 29.367088607594937 55.69620253164557\n",
      "62 0.18745511015355584 3.5348689277648924 29.367088607594937 55.69620253164557\n",
      "63 0.19773491930812598 3.675611534881592 29.367088607594937 55.69620253164557\n",
      "64 0.5461970990240574 2.253947444152832 29.367088607594937 55.69620253164557\n",
      "65 0.1907716762237251 3.1966072158813477 29.367088607594937 55.69620253164557\n",
      "66 0.4564701367288827 2.2314294677734376 29.367088607594937 55.69620253164557\n",
      "67 0.5551294410526753 2.1777721628189086 29.367088607594937 55.69620253164557\n",
      "68 0.7788302563071253 2.211253399848938 29.367088607594937 55.69620253164557\n",
      "69 0.7645553388893604 2.4639652183532714 29.367088607594937 55.69620253164557\n",
      "70 0.29562224592864517 2.9715606315612795 29.367088607594937 55.69620253164557\n",
      "71 0.494621777844429 2.3638280828475953 29.367088607594937 55.69620253164557\n",
      "72 0.39112190354466436 2.5254790742874147 29.367088607594937 55.69620253164557\n",
      "73 0.18934446145594125 3.6141430194854736 29.367088607594937 55.69620253164557\n",
      "74 0.08941101960316299 3.2770814683914185 29.367088607594937 55.69620253164557\n",
      "75 0.4072086886063218 2.5859445289611815 29.367088607594937 57.721518987341774\n",
      "76 0.1997792759172618 2.482917200279236 29.367088607594937 57.721518987341774\n",
      "77 0.8757127470850945 2.220254655456543 29.367088607594937 57.721518987341774\n",
      "78 0.10619322405345737 3.048439783477783 29.367088607594937 57.721518987341774\n",
      "79 0.6855184439301489 2.2767413478851317 29.367088607594937 57.721518987341774\n",
      "80 0.4504137116223574 2.144509373664856 29.367088607594937 57.721518987341774\n",
      "81 0.3430217406645418 2.5880712955474854 29.367088607594937 57.721518987341774\n",
      "82 0.5252388856709005 2.1342659198760985 29.367088607594937 57.721518987341774\n",
      "83 0.45978713174462316 2.528377265739441 29.367088607594937 57.721518987341774\n",
      "84 0.2051639124311507 2.6386194282531736 29.367088607594937 57.721518987341774\n",
      "85 0.3791389750957489 2.248117839431763 29.367088607594937 57.721518987341774\n",
      "86 0.19128197342902423 2.4724428199768065 29.367088607594937 57.721518987341774\n",
      "87 0.40498010500669485 2.05338417301178 29.367088607594937 57.721518987341774\n",
      "88 0.41238258132040506 2.43207622795105 29.367088607594937 57.721518987341774\n",
      "89 0.36273531360924244 2.8370093978881834 29.367088607594937 57.721518987341774\n",
      "90 0.48624046734869475 2.2637292755126954 29.367088607594937 57.721518987341774\n",
      "91 0.5592463077843188 2.0444121496200562 29.367088607594937 57.721518987341774\n",
      "92 0.2202482342138886 3.1523812688827513 29.367088607594937 57.721518987341774\n",
      "93 0.4605401436895133 2.6121858753204346 29.367088607594937 57.721518987341774\n",
      "94 0.41378264550566674 2.7014549700737 29.367088607594937 57.721518987341774\n",
      "95 0.4349462228417395 2.2574688313484192 29.367088607594937 57.721518987341774\n",
      "96 0.2662250703133643 2.6581456615447996 29.367088607594937 57.721518987341774\n",
      "97 0.5263885332942009 2.0985715356826784 29.367088607594937 57.721518987341774\n",
      "98 0.23807705439776178 2.5578583295822144 29.367088607594937 57.721518987341774\n",
      "99 0.24687360026314856 2.4339364212036134 29.367088607594937 57.848101265822784\n",
      "100 0.13039267457015813 2.687788924789429 29.367088607594937 57.848101265822784\n",
      "Training Done!\n",
      "Total time taken to Train: 447.2730975151062\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats = ((0.49139968, 0.48215841, 0.44653091), (0.24703223, 0.24348513, 0.26158784))\n",
    "partition = 'iid'\n",
    "transforms_cifar_train = tt.Compose([tt.ToTensor(),\n",
    "                                        tt.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
    "                                        tt.RandomHorizontalFlip(p=0.5),\n",
    "                                        tt.Normalize(*stats)])\n",
    "transforms_cifar_test = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "        transforms.Normalize(*stats)])\n",
    "\n",
    "cifar_data_train = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms_cifar_train)\n",
    "cifar_data_test = datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms_cifar_test)\n",
    "\n",
    "classes = np.array(list(cifar_data_train.class_to_idx.values()))\n",
    "classes_test = np.array(list(cifar_data_test.class_to_idx.values()))\n",
    "num_classes = len(classes_test)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Hyperparameters_List (H) = [rounds, client_fraction, number_of_clients, number_of_training_rounds_local, local_batch_size, lr_client]\n",
    "H = [commrounds, clientfr, numclient, clientepochs, clientbs, clientlr]\n",
    "\n",
    "if partition == 'noniid':\n",
    "    # (dataset, clients, total_shards, shards_size, num_shards_per_client):\n",
    "    # alpha for the Dirichlet distribution\n",
    "    data_dict = non_iid_partition(cifar_data_train, 100, float(alpha_partition))\n",
    "    print(len(cifar_data_train))\n",
    "else:\n",
    "    data_dict = iid_partition(cifar_data_train, 100)  # Uncomment for idd_partition\n",
    "\n",
    "if norm == 'gn':\n",
    "    cifar_cnn = resnet.ResNet(resnet.Bottleneck, [3, 4, 6, 3], num_classes=10, zero_init_residual=False, groups=1,\n",
    "                                width_per_group=64, replace_stride_with_dilation=None, norm_layer=MyGroupNorm)\n",
    "else:\n",
    "    cifar_cnn = resnet.ResNet(resnet.Bottleneck, [3, 4, 6, 3], num_classes=10, zero_init_residual=False, groups=1,\n",
    "                                width_per_group=64, replace_stride_with_dilation=None)\n",
    "\n",
    "cifar_cnn.cuda()\n",
    "\n",
    "plot_str = partition + '_' + norm + '_' + 'comm_rounds_' + str(commrounds) + '_clientfr_' + str(\n",
    "    clientfr) + '_numclients_' + str(numclient) + '_clientepochs_' + str(\n",
    "    clientepochs) + '_clientbs_' + str(clientbs) + '_clientLR_' + str(clientlr)\n",
    "print(plot_str)\n",
    "\n",
    "trained_model = training(cifar_cnn, H[0], H[4], H[5], cifar_data_train, data_dict, H[1], H[2], H[3], plot_str,\n",
    "                            \"green\", cifar_data_test, 128, criterion, num_classes, classes_test, sch_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "############################################\n",
    "#### Initializing models and optimizer  ####\n",
    "############################################\n",
    "\n",
    "#### global model ##########\n",
    "global_model =  resnet.ResNet(resnet.Bottleneck, [3, 4, 6, 3], num_classes=10, zero_init_residual=False, \n",
    "                             groups=1, width_per_group=64, replace_stride_with_dilation=None).cuda()\n",
    "\n",
    "############## client models ##############\n",
    "client_models = [ resnet.ResNet(resnet.Bottleneck, [3, 4, 6, 3], num_classes=10, zero_init_residual=False, groups=1, width_per_group=64, replace_stride_with_dilation=None).cuda() for _ in range(num_selected)]\n",
    "for model in client_models:\n",
    "    model.load_state_dict(global_model.state_dict()) ### initial synchronizing with global model \n",
    "\n",
    "############### optimizers ################\n",
    "opt = [optim.SGD(model.parameters(), lr=0.1) for model in client_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(num_selected)):\n\u001b[0;32m---> 14\u001b[0m     loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m client_update(client_models[i], opt[i], train_loader[client_idx[i]], epoch\u001b[39m=\u001b[39mepochs)\n\u001b[1;32m     16\u001b[0m losses_train\u001b[39m.\u001b[39mappend(loss)\n\u001b[1;32m     17\u001b[0m \u001b[39m# server aggregate\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "###### List containing info about learning #########\n",
    "losses_train = []\n",
    "losses_test = []\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "# Runnining FL\n",
    "\n",
    "for r in range(num_rounds):\n",
    "    # select random clients\n",
    "    client_idx = np.random.permutation(num_clients)[:num_selected]\n",
    "    # client update\n",
    "    loss = 0\n",
    "    for i in tqdm(range(num_selected)):\n",
    "        loss += client_update(client_models[i], opt[i], train_loader[client_idx[i]], epoch=epochs)\n",
    "    \n",
    "    losses_train.append(loss)\n",
    "    # server aggregate\n",
    "    server_aggregate(global_model, client_models)\n",
    "    \n",
    "    test_loss, acc = test(global_model, test_loader)\n",
    "    losses_test.append(test_loss)\n",
    "    acc_test.append(acc)\n",
    "    print('%d-th round' % r)\n",
    "    print('average train loss %0.3g | test loss %0.3g | test acc: %0.3f' % (loss / num_selected, test_loss, acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Data Per Client: [521, 260, 1327, 2180, 284, 1279, 545, 805, 853, 1943], and goal amount of data each client has per class: 2180\n",
      "Untouched: 2606 Noise: 19194, Classes: [4, 5, 6, 7, 8, 9]\n",
      "Labels: [[   0 2180]\n",
      " [   1 2180]\n",
      " [   2 2180]\n",
      " [   3 2180]\n",
      " [   4 2180]\n",
      " [   5 2180]\n",
      " [   6 2180]\n",
      " [   7 2180]\n",
      " [   8 2180]\n",
      " [   9 2180]]\n",
      "Untouched: 1303 Noise: 20497, Classes: [4, 5, 6, 7, 8, 9]\n",
      "Labels: [[   0 2180]\n",
      " [   1 2180]\n",
      " [   2 2180]\n",
      " [   3 2180]\n",
      " [   4 2180]\n",
      " [   5 2180]\n",
      " [   6 2180]\n",
      " [   7 2180]\n",
      " [   8 2180]\n",
      " [   9 2180]]\n",
      "Untouched: 6635 Noise: 15165, Classes: [8, 9, 0, 1, 2]\n",
      "Labels: [[   0 2180]\n",
      " [   1 2180]\n",
      " [   2 2180]\n",
      " [   3 2180]\n",
      " [   4 2180]\n",
      " [   5 2180]\n",
      " [   6 2180]\n",
      " [   7 2180]\n",
      " [   8 2180]\n",
      " [   9 2180]]\n",
      "Untouched: 10900 Noise: 10900, Classes: [4, 5, 6, 7, 8]\n",
      "Labels: [[   0 2180]\n",
      " [   1 2180]\n",
      " [   2 2180]\n",
      " [   3 2180]\n",
      " [   4 2180]\n",
      " [   5 2180]\n",
      " [   6 2180]\n",
      " [   7 2180]\n",
      " [   8 2180]\n",
      " [   9 2180]]\n",
      "Untouched: 1421 Noise: 20379, Classes: [6, 7, 8, 9, 0, 1]\n",
      "Labels: [[   0 2180]\n",
      " [   1 2180]\n",
      " [   2 2180]\n",
      " [   3 2180]\n",
      " [   4 2180]\n",
      " [   5 2180]\n",
      " [   6 2180]\n",
      " [   7 2180]\n",
      " [   8 2180]\n",
      " [   9 2180]]\n",
      "Untouched: 6398 Noise: 15402, Classes: [5, 6, 7, 8, 9, 0]\n",
      "Labels: [[   0 2180]\n",
      " [   1 2180]\n",
      " [   2 2180]\n",
      " [   3 2180]\n",
      " [   4 2180]\n",
      " [   5 2180]\n",
      " [   6 2180]\n",
      " [   7 2180]\n",
      " [   8 2180]\n",
      " [   9 2180]]\n",
      "Untouched: 2725 Noise: 19075, Classes: [1, 2, 3, 4, 5]\n",
      "Labels: [[   0 2180]\n",
      " [   1 2180]\n",
      " [   2 2180]\n",
      " [   3 2180]\n",
      " [   4 2180]\n",
      " [   5 2180]\n",
      " [   6 2180]\n",
      " [   7 2180]\n",
      " [   8 2180]\n",
      " [   9 2180]]\n",
      "Untouched: 4028 Noise: 17772, Classes: [1, 2, 3, 4, 5, 6, 7]\n",
      "Labels: [[   0 2180]\n",
      " [   1 2180]\n",
      " [   2 2180]\n",
      " [   3 2180]\n",
      " [   4 2180]\n",
      " [   5 2180]\n",
      " [   6 2180]\n",
      " [   7 2180]\n",
      " [   8 2180]\n",
      " [   9 2180]]\n",
      "Untouched: 4265 Noise: 17535, Classes: [2, 3, 4, 5, 6, 7, 8, 9, 0]\n",
      "Labels: [[   0 2180]\n",
      " [   1 2180]\n",
      " [   2 2180]\n",
      " [   3 2180]\n",
      " [   4 2180]\n",
      " [   5 2180]\n",
      " [   6 2180]\n",
      " [   7 2180]\n",
      " [   8 2180]\n",
      " [   9 2180]]\n",
      "Untouched: 9719 Noise: 31701, Classes: [3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1]\n",
      "Labels: [[   0 4360]\n",
      " [   1 4360]\n",
      " [   2 2180]\n",
      " [   3 4360]\n",
      " [   4 4360]\n",
      " [   5 4360]\n",
      " [   6 4360]\n",
      " [   7 4360]\n",
      " [   8 4360]\n",
      " [   9 4360]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2118/2454458452.py:80: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  clients_split = np.array(clients_split)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = get_cifar10()\n",
    "split = split_image_data(x_train, y_train, n_clients=num_clients, classes_per_client=classes_pc, verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50 Rounds\n",
    "100 standard deviation gaussian noise accuracy hovered around .163, (all samples)\n",
    "\n",
    "similar results with half samples at 50 std.\n",
    "\n",
    "20% application on 20 std accuracy a little better at .2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "std 3 80% application accuracy close to .74"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Each Client Gets 2 classes\n",
    "this leaves us with accuracy hovering around .35 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".3 application .7 accuracy\n",
    "\n",
    ".8 application .8 accuracy later\n",
    "\n",
    "Does well on full application (std 3) with around .7 accuracy\n",
    "\n",
    ".8 application 20 gaussian does well still\n",
    "\n",
    ".8 application 50 guassian .6 accuracy\n",
    "\n",
    ".65 accuracy .2 normal .2 gaussian .6 natural images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
