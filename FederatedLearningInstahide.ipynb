{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###############################\n",
    "##### importing libraries #####\n",
    "###############################\n",
    "\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.dataset import Dataset\n",
    "torch.backends.cudnn.benchmark=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Hyperparameters for federated learning #########\n",
    "num_clients = 20\n",
    "num_selected = 6\n",
    "num_rounds = 150\n",
    "epochs = 5\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('cifar10_mixed/encryption.npy')\n",
    "labels = np.load('cifar10_mixed/label.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image as im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = im.fromarray(data[1], 'RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.save('sample2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16742045, 0.        , 0.        , 0.16031678, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 32, 32, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "add = 0\n",
    "for i, image in enumerate(data):\n",
    "    dataset.append((torch.tensor(np.transpose(image)), np.argmax(labels[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2957/3255302352.py:14: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  traindata = np.array(dataset)\n",
      "/tmp/ipykernel_2957/3255302352.py:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  traindata = np.array(dataset)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#############################################################\n",
    "##### Creating desired data distribution among clients  #####\n",
    "#############################################################\n",
    "\n",
    "# Image augmentation \n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Loading CIFAR10 using torchvision.datasets\n",
    "traindata = np.array(dataset)\n",
    "# train_fake_data = datasets.CIFAR10('./data', train=True, download=True)\n",
    "\n",
    "# Dividing the training data into num_clients, with each client having equal number of images\n",
    "traindata_split = torch.utils.data.random_split(traindata, [int(traindata.shape[0] / num_clients) for _ in range(num_clients)])\n",
    "\n",
    "# Creating a pytorch loader for a Deep Learning model\n",
    "train_loader = [torch.utils.data.DataLoader(x, batch_size=batch_size, shuffle=True) for x in traindata_split]\n",
    "\n",
    "# Normalizing the test images\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Loading the test iamges and thus converting them into a test_loader\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10('./data', train=False, transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "        ), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images, labels = next(iter(train_loader[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2957/1474642160.py:5: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  dataset = np.asarray(dataset)\n",
      "/tmp/ipykernel_2957/1474642160.py:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  dataset = np.asarray(dataset)\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "add = 0\n",
    "for i, image in enumerate(data):\n",
    "    dataset.append((torch.tensor(np.transpose(image)), labels[i]))\n",
    "dataset = np.asarray(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[tensor([[[-0.4124, -0.3718, -0.5027,  ...,  0.2789,  0.2813,  0.2092],\n",
       "                 [-0.4310,  0.3914,  0.4188,  ...,  0.2574,  0.3305,  0.2537],\n",
       "                 [ 0.4082,  0.4828, -0.3940,  ...,  0.1587, -0.3160, -0.3205],\n",
       "                 ...,\n",
       "                 [ 0.5846,  0.5688, -0.5358,  ..., -0.3715,  0.4111, -0.4737],\n",
       "                 [-0.5797, -0.5816, -0.5185,  ...,  0.4097,  0.3094, -0.2846],\n",
       "                 [ 0.5907,  0.6159,  0.4425,  ..., -0.3688,  0.3016, -0.2628]],\n",
       "\n",
       "                [[-0.3862,  0.3681,  0.5043,  ..., -0.2559, -0.2464,  0.1802],\n",
       "                 [-0.4079,  0.3867,  0.4276,  ..., -0.2452, -0.3100, -0.2386],\n",
       "                 [-0.3863,  0.4724,  0.4083,  ..., -0.1491, -0.3035, -0.3180],\n",
       "                 ...,\n",
       "                 [ 0.5922, -0.5747,  0.5272,  ...,  0.3122,  0.3473,  0.3944],\n",
       "                 [ 0.6031, -0.6036, -0.5289,  ...,  0.3972, -0.2938,  0.2614],\n",
       "                 [-0.6099, -0.6417, -0.4646,  ..., -0.3911,  0.3269, -0.3030]],\n",
       "\n",
       "                [[ 0.4712,  0.4315, -0.5930,  ...,  0.5730,  0.5052, -0.3585],\n",
       "                 [ 0.4977,  0.4627,  0.5021,  ..., -0.5379, -0.5536, -0.4005],\n",
       "                 [-0.4889, -0.5687,  0.4802,  ...,  0.3509, -0.4842, -0.4733],\n",
       "                 ...,\n",
       "                 [ 0.7347,  0.7482,  0.7234,  ..., -0.5001,  0.6280, -0.6874],\n",
       "                 [ 0.7282,  0.7473, -0.6641,  ...,  0.5780, -0.5703, -0.5191],\n",
       "                 [-0.7335,  0.7691,  0.5612,  ..., -0.6256, -0.6436, -0.5300]]]),\n",
       "        3],\n",
       "       [tensor([[[-0.0005, -0.0142, -0.0453,  ..., -0.1994,  0.1062, -0.0398],\n",
       "                 [ 0.0579, -0.0743, -0.0474,  ..., -0.2372, -0.1443, -0.0048],\n",
       "                 [ 0.1228, -0.1336, -0.1106,  ..., -0.2384, -0.1609,  0.0359],\n",
       "                 ...,\n",
       "                 [ 0.0203, -0.1473,  0.1023,  ..., -0.0416,  0.0382, -0.0101],\n",
       "                 [-0.0805,  0.0563,  0.0719,  ..., -0.0354, -0.0691,  0.0202],\n",
       "                 [-0.1695, -0.0297, -0.0169,  ...,  0.0272, -0.0659, -0.0526]],\n",
       "\n",
       "                [[-0.2843, -0.2716,  0.3198,  ...,  0.2788, -0.1925,  0.0487],\n",
       "                 [-0.2363,  0.2230, -0.2452,  ...,  0.3037, -0.2218, -0.0889],\n",
       "                 [-0.1773, -0.1724,  0.1895,  ...,  0.2959,  0.2331,  0.1204],\n",
       "                 ...,\n",
       "                 [-0.1564,  0.2496,  0.1706,  ..., -0.0653,  0.0805, -0.1359],\n",
       "                 [ 0.0470, -0.1493, -0.1385,  ...,  0.0639, -0.0336, -0.0855],\n",
       "                 [-0.0481, -0.0628,  0.0558,  ..., -0.0744,  0.0362, -0.0485]],\n",
       "\n",
       "                [[ 0.3729, -0.3572,  0.3945,  ..., -0.4418, -0.3701,  0.2512],\n",
       "                 [-0.2955,  0.2869, -0.3116,  ...,  0.4698, -0.3978,  0.2796],\n",
       "                 [-0.2043, -0.2107, -0.2373,  ..., -0.4661,  0.3994,  0.2931],\n",
       "                 ...,\n",
       "                 [-0.3154,  0.3862,  0.3012,  ...,  0.2013, -0.1876, -0.2455],\n",
       "                 [-0.2226,  0.3071, -0.2871,  ...,  0.1708, -0.1371, -0.1900],\n",
       "                 [ 0.1454, -0.2341,  0.2102,  ...,  0.1707,  0.1402, -0.1632]]]),\n",
       "        7],\n",
       "       [tensor([[[-0.0461,  0.1414, -0.1420,  ..., -0.2714,  0.2620,  0.1725],\n",
       "                 [-0.0136, -0.1414,  0.1253,  ..., -0.2332,  0.2959,  0.2156],\n",
       "                 [ 0.0113,  0.0424, -0.0454,  ..., -0.1884, -0.2529,  0.1859],\n",
       "                 ...,\n",
       "                 [-0.4240, -0.4753, -0.4767,  ..., -0.0824, -0.0029, -0.1324],\n",
       "                 [ 0.4887,  0.4186, -0.4655,  ..., -0.0855,  0.0249,  0.0545],\n",
       "                 [ 0.5440, -0.4598, -0.4325,  ...,  0.0768, -0.0615, -0.0422]],\n",
       "\n",
       "                [[-0.0124,  0.1767, -0.1427,  ...,  0.3822, -0.3863, -0.2958],\n",
       "                 [-0.0333, -0.1812,  0.1250,  ..., -0.3263,  0.3933, -0.3111],\n",
       "                 [-0.0130,  0.0389, -0.0033,  ..., -0.2861, -0.3651, -0.2894],\n",
       "                 ...,\n",
       "                 [-0.4223,  0.4704,  0.4684,  ...,  0.0304, -0.0565,  0.1729],\n",
       "                 [ 0.4980,  0.4274,  0.4600,  ...,  0.0348, -0.0171, -0.0955],\n",
       "                 [ 0.5690,  0.4652,  0.4194,  ...,  0.0957, -0.0718, -0.0157]],\n",
       "\n",
       "                [[ 0.0347, -0.2118, -0.2476,  ..., -0.4014,  0.4138,  0.3331],\n",
       "                 [-0.0651, -0.1992,  0.1652,  ...,  0.3630, -0.4250, -0.3437],\n",
       "                 [ 0.0431, -0.1305,  0.0993,  ...,  0.3102, -0.3749,  0.3030],\n",
       "                 ...,\n",
       "                 [ 0.4798, -0.5287,  0.5140,  ...,  0.0968, -0.1526, -0.2240],\n",
       "                 [-0.5501, -0.4737,  0.4952,  ...,  0.0852, -0.0929, -0.1659],\n",
       "                 [ 0.6141, -0.5013, -0.4418,  ...,  0.1653,  0.1204, -0.1229]]]),\n",
       "        0],\n",
       "       ...,\n",
       "       [tensor([[[-0.1812,  0.2224, -0.0658,  ..., -0.5626,  0.4288, -0.2220],\n",
       "                 [-0.2932,  0.2398,  0.1077,  ...,  0.5148,  0.3701, -0.2027],\n",
       "                 [-0.3416,  0.3117, -0.2214,  ..., -0.4509,  0.3953, -0.2178],\n",
       "                 ...,\n",
       "                 [ 0.0869, -0.1793, -0.2716,  ..., -0.0294, -0.0782,  0.1796],\n",
       "                 [ 0.1335,  0.1341,  0.1062,  ...,  0.0800,  0.0210, -0.0539],\n",
       "                 [ 0.1088,  0.0582, -0.0345,  ..., -0.1875, -0.0487,  0.0023]],\n",
       "\n",
       "                [[ 0.1986,  0.2556,  0.1391,  ...,  0.4342, -0.3231,  0.1346],\n",
       "                 [ 0.3035,  0.2602, -0.1613,  ...,  0.3866,  0.2690,  0.1119],\n",
       "                 [ 0.3583,  0.3309,  0.2431,  ..., -0.3236,  0.2929, -0.1217],\n",
       "                 ...,\n",
       "                 [ 0.0236, -0.0523,  0.1352,  ...,  0.0873, -0.0311, -0.0739],\n",
       "                 [ 0.0042,  0.0071,  0.0320,  ..., -0.0478,  0.0921, -0.0538],\n",
       "                 [ 0.0350,  0.0816, -0.1028,  ..., -0.0586,  0.0716,  0.1151]],\n",
       "\n",
       "                [[ 0.2124,  0.2922, -0.1859,  ..., -0.4347, -0.3377,  0.1316],\n",
       "                 [ 0.3147,  0.2837, -0.1991,  ..., -0.3914,  0.2816, -0.1138],\n",
       "                 [-0.3691, -0.3456, -0.2713,  ...,  0.3148, -0.2856,  0.1086],\n",
       "                 ...,\n",
       "                 [ 0.1654,  0.0780, -0.0251,  ..., -0.1359, -0.0820,  0.0150],\n",
       "                 [ 0.1071,  0.0953, -0.1057,  ..., -0.0961, -0.1390,  0.1081],\n",
       "                 [-0.0999, -0.1372,  0.1418,  ...,  0.0113, -0.1202, -0.1661]]]),\n",
       "        5],\n",
       "       [tensor([[[-0.0393, -0.0572,  0.0739,  ..., -0.1066,  0.0482, -0.0196],\n",
       "                 [ 0.0460,  0.0589, -0.0617,  ..., -0.1338, -0.0799, -0.0503],\n",
       "                 [ 0.0559,  0.0257,  0.0387,  ...,  0.1942,  0.1193,  0.0692],\n",
       "                 ...,\n",
       "                 [-0.0578, -0.0167, -0.0331,  ...,  0.3977,  0.3045,  0.1134],\n",
       "                 [ 0.0339,  0.0518,  0.0078,  ...,  0.1664,  0.1006, -0.0204],\n",
       "                 [-0.0256,  0.0147, -0.0434,  ..., -0.0292,  0.0388, -0.0709]],\n",
       "\n",
       "                [[-0.0021, -0.0042,  0.0062,  ..., -0.1391,  0.0229,  0.0863],\n",
       "                 [ 0.0170,  0.0132, -0.0021,  ...,  0.1805,  0.0796, -0.0086],\n",
       "                 [-0.0309, -0.0133,  0.0116,  ...,  0.2497,  0.1340, -0.0562],\n",
       "                 ...,\n",
       "                 [-0.0810, -0.1424, -0.2138,  ..., -0.4065, -0.3098,  0.1415],\n",
       "                 [ 0.0553,  0.0582, -0.1164,  ...,  0.1304,  0.0377, -0.0481],\n",
       "                 [ 0.0800, -0.0859, -0.1321,  ..., -0.0186, -0.1196, -0.1263]],\n",
       "\n",
       "                [[ 0.1444,  0.1408,  0.1400,  ...,  0.3172, -0.2046, -0.0754],\n",
       "                 [ 0.1228, -0.1263,  0.1364,  ..., -0.3378,  0.2371, -0.1414],\n",
       "                 [ 0.0983,  0.1387,  0.1452,  ..., -0.3779,  0.2419, -0.1082],\n",
       "                 ...,\n",
       "                 [-0.1530,  0.1989,  0.2454,  ..., -0.5811,  0.4603, -0.2452],\n",
       "                 [-0.1258,  0.1293, -0.1827,  ...,  0.2942, -0.1886,  0.0632],\n",
       "                 [-0.1644,  0.1701, -0.2237,  ..., -0.0945,  0.0280,  0.0406]]]),\n",
       "        7],\n",
       "       [tensor([[[-5.5889e-02,  1.5894e-03, -2.2335e-02,  ...,  1.7157e-01,\n",
       "                  -1.8292e-01,  2.1935e-02],\n",
       "                 [ 3.0009e-03, -7.6409e-02, -2.5023e-02,  ..., -1.6255e-01,\n",
       "                   2.0523e-01, -1.3275e-01],\n",
       "                 [-3.9414e-02, -9.0412e-02,  5.0083e-02,  ...,  2.0585e-01,\n",
       "                   2.3831e-01,  1.6746e-01],\n",
       "                 ...,\n",
       "                 [-1.6163e-01, -1.4867e-01, -1.7789e-01,  ...,  3.2255e-01,\n",
       "                   2.6562e-01,  2.7286e-01],\n",
       "                 [-4.3815e-02,  6.9284e-02,  1.0375e-01,  ..., -2.7977e-01,\n",
       "                   2.3115e-01, -2.1854e-01],\n",
       "                 [-2.2571e-03, -6.2656e-02,  1.0917e-01,  ..., -2.1365e-01,\n",
       "                  -1.5662e-01,  1.3324e-01]],\n",
       "\n",
       "                [[ 1.4796e-01,  9.7317e-02,  6.9122e-02,  ..., -1.6610e-01,\n",
       "                  -1.8648e-01, -4.1221e-02],\n",
       "                 [ 8.7847e-02,  2.0105e-02, -6.0911e-02,  ..., -1.7645e-01,\n",
       "                   2.2041e-01,  1.5497e-01],\n",
       "                 [ 1.0853e-01, -1.6434e-03, -3.7038e-02,  ..., -2.2068e-01,\n",
       "                  -2.2888e-01,  1.3904e-01],\n",
       "                 ...,\n",
       "                 [-6.8777e-02,  2.9980e-02,  3.9175e-02,  ..., -4.1388e-01,\n",
       "                   3.3187e-01,  2.3304e-01],\n",
       "                 [-2.7964e-03, -5.3963e-03, -2.6210e-03,  ...,  3.5730e-01,\n",
       "                  -2.9069e-01,  1.9886e-01],\n",
       "                 [-1.0516e-03,  2.4456e-02, -2.9546e-02,  ...,  2.2369e-01,\n",
       "                   1.4775e-01, -9.6439e-02]],\n",
       "\n",
       "                [[-2.4766e-02, -6.2285e-02, -7.7203e-02,  ..., -3.1709e-01,\n",
       "                   2.5824e-01,  4.6753e-02],\n",
       "                 [ 5.0969e-02, -1.4533e-01, -8.2985e-02,  ...,  3.2019e-01,\n",
       "                   3.5228e-01, -2.5586e-01],\n",
       "                 [-1.5580e-04,  1.3317e-01,  7.2680e-02,  ..., -3.0801e-01,\n",
       "                   3.3850e-01,  2.4874e-01],\n",
       "                 ...,\n",
       "                 [ 2.7746e-02,  7.1580e-02,  7.0913e-02,  ..., -5.7550e-01,\n",
       "                  -4.8127e-01, -3.6080e-01],\n",
       "                 [ 6.8018e-02,  9.1887e-02,  1.0116e-01,  ..., -5.2508e-01,\n",
       "                   4.3725e-01, -3.1824e-01],\n",
       "                 [-4.6349e-02,  4.4009e-02,  5.1547e-02,  ..., -3.9702e-01,\n",
       "                   2.9968e-01, -2.3079e-01]]])                             ,\n",
       "        3]], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2957/439118079.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  np.array((data, labels))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (5000,32,32,3) into shape (5000,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[39m.\u001b[39;49marray((data, labels))\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (5000,32,32,3) into shape (5000,)"
     ]
    }
   ],
   "source": [
    "np.array((data, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([tensor([[[-0.4124, -0.3718, -0.5027,  ...,  0.2789,  0.2813,  0.2092],\n",
       "                [-0.4310,  0.3914,  0.4188,  ...,  0.2574,  0.3305,  0.2537],\n",
       "                [ 0.4082,  0.4828, -0.3940,  ...,  0.1587, -0.3160, -0.3205],\n",
       "                ...,\n",
       "                [ 0.5846,  0.5688, -0.5358,  ..., -0.3715,  0.4111, -0.4737],\n",
       "                [-0.5797, -0.5816, -0.5185,  ...,  0.4097,  0.3094, -0.2846],\n",
       "                [ 0.5907,  0.6159,  0.4425,  ..., -0.3688,  0.3016, -0.2628]],\n",
       "\n",
       "               [[-0.3862,  0.3681,  0.5043,  ..., -0.2559, -0.2464,  0.1802],\n",
       "                [-0.4079,  0.3867,  0.4276,  ..., -0.2452, -0.3100, -0.2386],\n",
       "                [-0.3863,  0.4724,  0.4083,  ..., -0.1491, -0.3035, -0.3180],\n",
       "                ...,\n",
       "                [ 0.5922, -0.5747,  0.5272,  ...,  0.3122,  0.3473,  0.3944],\n",
       "                [ 0.6031, -0.6036, -0.5289,  ...,  0.3972, -0.2938,  0.2614],\n",
       "                [-0.6099, -0.6417, -0.4646,  ..., -0.3911,  0.3269, -0.3030]],\n",
       "\n",
       "               [[ 0.4712,  0.4315, -0.5930,  ...,  0.5730,  0.5052, -0.3585],\n",
       "                [ 0.4977,  0.4627,  0.5021,  ..., -0.5379, -0.5536, -0.4005],\n",
       "                [-0.4889, -0.5687,  0.4802,  ...,  0.3509, -0.4842, -0.4733],\n",
       "                ...,\n",
       "                [ 0.7347,  0.7482,  0.7234,  ..., -0.5001,  0.6280, -0.6874],\n",
       "                [ 0.7282,  0.7473, -0.6641,  ...,  0.5780, -0.5703, -0.5191],\n",
       "                [-0.7335,  0.7691,  0.5612,  ..., -0.6256, -0.6436, -0.5300]]]),\n",
       "       3], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#################################\n",
    "##### Neural Network model #####\n",
    "#################################\n",
    "\n",
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        output = F.log_softmax(out, dim=1)\n",
    "        return output\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_update(client_model, optimizer, train_loader, epoch=5):\n",
    "    \"\"\"\n",
    "    This function updates/trains client model on client data\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for e in range(epoch):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output = client_model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def server_aggregate(global_model, client_models):\n",
    "    \"\"\"\n",
    "    This function has aggregation method 'mean'\n",
    "    \"\"\"\n",
    "    ### This will take simple mean of the weights of models ###\n",
    "    global_dict = global_model.state_dict()\n",
    "    for k in global_dict.keys():\n",
    "        global_dict[k] = torch.stack([client_models[i].state_dict()[k].float() for i in range(len(client_models))], 0).mean(0)\n",
    "    global_model.load_state_dict(global_dict)\n",
    "    for model in client_models:\n",
    "        model.load_state_dict(global_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test(global_model, test_loader):\n",
    "    \"\"\"This function test the global model on test data and returns test loss and test accuracy \"\"\"\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            output = global_model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    acc = correct / len(test_loader.dataset)\n",
    "\n",
    "    return test_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "############################################\n",
    "#### Initializing models and optimizer  ####\n",
    "############################################\n",
    "\n",
    "#### global model ##########\n",
    "global_model =  VGG('VGG19').cuda()\n",
    "\n",
    "############## client models ##############\n",
    "client_models = [ VGG('VGG19').cuda() for _ in range(num_selected)]\n",
    "for model in client_models:\n",
    "    model.load_state_dict(global_model.state_dict()) ### initial synchronizing with global model \n",
    "\n",
    "############### optimizers ################\n",
    "opt = [optim.SGD(model.parameters(), lr=0.1) for model in client_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(num_selected)):\n\u001b[0;32m---> 14\u001b[0m     loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m client_update(client_models[i], opt[i], train_loader[client_idx[i]], epoch\u001b[39m=\u001b[39;49mepochs)\n\u001b[1;32m     16\u001b[0m losses_train\u001b[39m.\u001b[39mappend(loss)\n\u001b[1;32m     17\u001b[0m \u001b[39m# server aggregate\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[16], line 7\u001b[0m, in \u001b[0;36mclient_update\u001b[0;34m(client_model, optimizer, train_loader, epoch)\u001b[0m\n\u001b[1;32m      5\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epoch):\n\u001b[0;32m----> 7\u001b[0m     \u001b[39mfor\u001b[39;00m batch_idx, (data, target) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m      8\u001b[0m         data, target \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcuda(), target\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m      9\u001b[0m         optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py:61\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 61\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39;49mdefault_collate_fn_map)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/collate.py:120\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39mif\u001b[39;00m collate_fn_map \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[39mif\u001b[39;00m elem_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 120\u001b[0m         \u001b[39mreturn\u001b[39;00m collate_fn_map[elem_type](batch, collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map)\n\u001b[1;32m    122\u001b[0m     \u001b[39mfor\u001b[39;00m collate_type \u001b[39min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    123\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/collate.py:170\u001b[0m, in \u001b[0;36mcollate_numpy_array_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39m# array of string classes and object\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[39mif\u001b[39;00m np_str_obj_array_pattern\u001b[39m.\u001b[39msearch(elem\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mstr) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[39m.\u001b[39mformat(elem\u001b[39m.\u001b[39mdtype))\n\u001b[1;32m    172\u001b[0m \u001b[39mreturn\u001b[39;00m collate([torch\u001b[39m.\u001b[39mas_tensor(b) \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m batch], collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map)\n",
      "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found object"
     ]
    }
   ],
   "source": [
    "###### List containing info about learning #########\n",
    "losses_train = []\n",
    "losses_test = []\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "# Runnining FL\n",
    "\n",
    "for r in range(num_rounds):\n",
    "    # select random clients\n",
    "    client_idx = np.random.permutation(num_clients)[:num_selected]\n",
    "    # client update\n",
    "    loss = 0\n",
    "    for i in tqdm(range(num_selected)):\n",
    "        loss += client_update(client_models[i], opt[i], train_loader[client_idx[i]], epoch=epochs)\n",
    "    \n",
    "    losses_train.append(loss)\n",
    "    # server aggregate\n",
    "    server_aggregate(global_model, client_models)\n",
    "    \n",
    "    test_loss, acc = test(global_model, test_loader)\n",
    "    losses_test.append(test_loss)\n",
    "    acc_test.append(acc)\n",
    "    print('%d-th round' % r)\n",
    "    print('average train loss %0.3g | test loss %0.3g | test acc: %0.3f' % (loss / num_selected, test_loss, acc))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50 Rounds\n",
    "100 standard deviation gaussian noise accuracy hovered around .163, (all samples)\n",
    "\n",
    "similar results with half samples at 50 std.\n",
    "\n",
    "20% application on 20 std accuracy a little better at .2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "std 3 80% application accuracy close to .74"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
